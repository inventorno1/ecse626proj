{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breaking down cDPM code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sample_some_indices`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_some_indices(max_indices=20, T=128):\n",
    "    # print(\"Sampling indices, T is \", T)\n",
    "    s = th.randint(low=1, high=max_indices+1, size=())\n",
    "    max_scale = T / (s-0.999)\n",
    "    scale = np.exp(np.random.rand() * np.log(max_scale))\n",
    "    pos = th.rand(()) * (T - scale*(s-1))\n",
    "    # print(f\"s: {s}, max_sacle: {max_scale}, pos: {pos}\")\n",
    "    indices = [int(pos+i*scale) for i in range(s)]\n",
    "    print(indices)\n",
    "    # do some recursion if we have somehow failed to satisfy the consrtaints\n",
    "    if all(i<T and i>=0 for i in indices):\n",
    "        return indices\n",
    "    else:\n",
    "        print('warning: sampled invalid indices', [int(pos+i*scale) for i in range(s)], 'trying again')\n",
    "        # exit()\n",
    "        return self.sample_some_indices(max_indices, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_indices=20\n",
    "T=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: 12, max_sacle: 11.635305404663086, pos: 74.12855529785156\n",
      "scale: 4.387874603271484\n",
      "[74, 78, 82, 87, 91, 96, 100, 104, 109, 113, 118, 122]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1643087/2914927780.py:3: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  scale = np.exp(np.random.rand() * np.log(max_scale))\n"
     ]
    }
   ],
   "source": [
    "s = th.randint(low=1, high=max_indices+1, size=())\n",
    "max_scale = T / (s-0.999)\n",
    "scale = np.exp(np.random.rand() * np.log(max_scale))\n",
    "pos = th.rand(()) * (T - scale*(s-1))\n",
    "# print(f\"s: {s}, max_sacle: {max_scale}, pos: {pos}\")\n",
    "indices = [int(pos+i*scale) for i in range(s)]\n",
    "print(f\"s: {s}, max_sacle: {max_scale}, pos: {pos}\")\n",
    "print(f\"scale: {scale}\")\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function randomly samples a number of indices `s`as well as a starting position `pos` and spacing `scale` to return `s` roughly linearly spaced indices between 1 and 128."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sample_all_masks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_all_masks(self, batch1, batch2=None, gather=True, set_masks={'obs': (), 'latent': ()}):\n",
    "    # print(\"Inside sample_all_masks\")\n",
    "    N = self.max_frames\n",
    "    # print(f'batch1 {batch1.shape}, {batch2.shape}, {N}')\n",
    "    B, T, *_ = batch1.shape\n",
    "    masks = {k: th.zeros_like(batch1[:, :, :1, :1, :1]) for k in ['obs', 'latent']}\n",
    "    for obs_row, latent_row in zip(*[masks[k] for k in ['obs', 'latent']]):\n",
    "        latent_row[self.sample_some_indices(max_indices=N, T=T)] = 1.\n",
    "        while True:\n",
    "            mask = obs_row if th.rand(()) < 0.5 else latent_row\n",
    "            indices = th.tensor(self.sample_some_indices(max_indices=N, T=T))\n",
    "            taken = (obs_row[indices] + latent_row[indices]).view(-1)\n",
    "            indices = indices[taken == 0]  # remove indices that are already used in a mask\n",
    "            if len(indices) > N - sum(obs_row) - sum(latent_row):\n",
    "                break\n",
    "            mask[indices] = 1.\n",
    "    if len(set_masks['obs']) > 0:  # set_masks allow us to choose informative masks for logging\n",
    "        for k in masks:\n",
    "            set_values = set_masks[k]\n",
    "            n_set = min(len(set_values), len(masks[k]))\n",
    "            masks[k][:n_set] = set_values[:n_set]\n",
    "    any_mask = (masks['obs'] + masks['latent']).clip(max=1)\n",
    "    if not gather:\n",
    "        return batch1, masks['obs'], masks['latent']\n",
    "    batch, (obs_mask, latent_mask), frame_indices =\\\n",
    "        self.prepare_training_batch(\n",
    "            any_mask, batch1, batch2, (masks['obs'], masks['latent'])\n",
    "        )\n",
    "    return batch, frame_indices, obs_mask, latent_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20 # max_frames is same as maximum number of slices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Makes dictionary of obs and latent masks\n",
    "* In latent_row it sets sampled indices from `sample_some_indices` to one, so a one hot encoding of the condition (?) slices\n",
    "* w.p. 0.5 choose mask to be the obs row otherwise the latent\n",
    "* sample more indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = th.zeros((1, 128, 1, 128, 128)) # B, T, C, H, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = {k: th.zeros_like(batch1[:, :, :1, :1, :1]) for k in ['obs', 'latent']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes obs and latent masks with a batch size equal to the batch size used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "del obs_row, latent_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for obs_row, latent_row in zip(*[masks[k] for k in ['obs', 'latent']]):\n",
    "    print(latent_row.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this iterates across the batch dimension of the masks to do the code for each part of the mask in that batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_row = masks['latent'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56, 65, 74, 83, 92, 101, 109, 118, 127]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1643087/3152650083.py:5: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  scale = np.exp(np.random.rand() * np.log(max_scale))\n"
     ]
    }
   ],
   "source": [
    "latent_row[sample_some_indices(max_indices=N, T=T)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78, 87]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1643087/3152650083.py:5: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  scale = np.exp(np.random.rand() * np.log(max_scale))\n"
     ]
    }
   ],
   "source": [
    "indices = th.tensor(sample_some_indices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "taken = (obs_row[indices] + latent_row[indices]).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([78, 87])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[taken == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 61, 63, 66, 69, 71, 74, 77, 79, 82, 85, 87, 90]\n",
      "[80, 82, 84, 85, 87, 89, 90, 92, 94, 96]\n",
      "[71, 72, 74, 75, 77, 78, 80, 81, 83, 84, 86, 87, 89, 90, 92, 93, 95, 96, 97, 99]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1643087/3152650083.py:5: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  scale = np.exp(np.random.rand() * np.log(max_scale))\n"
     ]
    }
   ],
   "source": [
    "for obs_row, latent_row in zip(*[masks[k] for k in ['obs', 'latent']]):\n",
    "    latent_row[sample_some_indices(max_indices=N, T=T)] = 1.\n",
    "    while True:\n",
    "        mask = obs_row if th.rand(()) < 0.5 else latent_row\n",
    "        indices = th.tensor(sample_some_indices(max_indices=N, T=T))\n",
    "        taken = (obs_row[indices] + latent_row[indices]).view(-1)\n",
    "        indices = indices[taken == 0]  # remove indices that are already used in a mask\n",
    "        if len(indices) > N - sum(obs_row) - sum(latent_row):\n",
    "            break\n",
    "        mask[indices] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.sum(masks['obs'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19.)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.sum(masks['latent'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure what it's doing exactly, it's used in conjunction with `prepare_training_batch` to get everything ready. Think can just do my own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "any_mask = (masks['obs'] + masks['latent']).clip(max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_batch(mask, batch1, batch2, tensors, max_frames=20, pad_with_random_frames=False):\n",
    "    \"\"\"\n",
    "    Prepare training batch by selecting frames from batch1 according to mask, appending uniformly sampled frames\n",
    "    from batch2, and selecting the corresponding elements from tensors (usually obs_mask and latent_mask).\n",
    "    \"\"\"\n",
    "    B, T, *_ = mask.shape\n",
    "    mask = mask.view(B, T)  # remove unit C, H, W dims\n",
    "    effective_T = max_frames if pad_with_random_frames else mask.sum(dim=1).max().int()\n",
    "    indices = th.zeros_like(mask[:, :effective_T], dtype=th.int64)\n",
    "    new_batch = th.zeros_like(batch1[:, :effective_T])\n",
    "    new_tensors = [th.zeros_like(t[:, :effective_T]) for t in tensors]\n",
    "    for b in range(B):\n",
    "        instance_T = mask[b].sum().int()\n",
    "        indices[b, :instance_T] = mask[b].nonzero().flatten()\n",
    "        indices[b, instance_T:] = th.randint_like(indices[b, instance_T:], high=T) if pad_with_random_frames else 0\n",
    "        new_batch[b, :instance_T] = batch1[b][mask[b]==1]\n",
    "        new_batch[b, instance_T:] = (batch1 if batch2 is None else batch2)[b][indices[b, instance_T:]]\n",
    "        for new_t, t in zip(new_tensors, tensors):\n",
    "            new_t[b, :instance_T] = t[b][mask[b]==1]\n",
    "            new_t[b, instance_T:] = t[b][indices[b, instance_T:]]\n",
    "    return new_batch, new_tensors, indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, (obs_mask, latent_mask), frame_indices = prepare_training_batch(any_mask, batch1, None, (masks['obs'], masks['latent']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19, 1, 128, 128])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19, 1, 1, 1])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19, 1, 1, 1])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[58, 61, 63, 66, 69, 71, 74, 77, 79, 80, 82, 84, 85, 87, 89, 90, 92, 94,\n",
       "         96]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My own implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_indices(max_slices=20, num_slices=128):\n",
    "\n",
    "    total_indices = random.randint(1, max_slices)\n",
    "\n",
    "    indices = random.sample(range(1,num_slices), total_indices)\n",
    "\n",
    "    target_size = random.randint(1, len(indices))\n",
    "    target = random.sample(indices, target_size)\n",
    "    condition = [index for index in indices if index not in target]\n",
    "\n",
    "    return condition, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [sample_indices()[1] for i in range(100000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "singletons = []\n",
    "for target in test_list:\n",
    "    if len(target) == 1:\n",
    "        i += 1\n",
    "        singletons += target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17942"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i/100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([121., 125., 132., 125., 152., 127., 128., 131., 145., 129., 149.,\n",
       "        122., 144., 140., 147., 146., 143., 129., 128., 158., 130., 144.,\n",
       "        123., 125., 127., 147., 146., 131., 140., 140., 148., 178., 151.,\n",
       "        147., 156., 145., 139., 137., 146., 139., 136., 148., 141., 128.,\n",
       "        134., 135., 154., 120., 139., 138., 141., 133., 143., 168., 136.,\n",
       "        153., 155., 157., 143., 138., 139., 154., 137., 141., 146., 153.,\n",
       "        122., 120., 156., 138., 139., 140., 130., 143., 137., 138., 139.,\n",
       "        157., 128., 145., 135., 130., 150., 150., 154., 150., 163., 142.,\n",
       "        149., 143., 133., 134., 129., 150., 137., 147., 124., 136., 130.,\n",
       "        143., 180., 128., 149., 141., 145., 152., 121., 141., 161., 135.,\n",
       "        166., 132., 139., 130., 154., 141., 148., 133., 128., 156., 131.,\n",
       "        152., 151., 146., 135., 161., 155.]),\n",
       " array([  1.        ,   1.99212598,   2.98425197,   3.97637795,\n",
       "          4.96850394,   5.96062992,   6.95275591,   7.94488189,\n",
       "          8.93700787,   9.92913386,  10.92125984,  11.91338583,\n",
       "         12.90551181,  13.8976378 ,  14.88976378,  15.88188976,\n",
       "         16.87401575,  17.86614173,  18.85826772,  19.8503937 ,\n",
       "         20.84251969,  21.83464567,  22.82677165,  23.81889764,\n",
       "         24.81102362,  25.80314961,  26.79527559,  27.78740157,\n",
       "         28.77952756,  29.77165354,  30.76377953,  31.75590551,\n",
       "         32.7480315 ,  33.74015748,  34.73228346,  35.72440945,\n",
       "         36.71653543,  37.70866142,  38.7007874 ,  39.69291339,\n",
       "         40.68503937,  41.67716535,  42.66929134,  43.66141732,\n",
       "         44.65354331,  45.64566929,  46.63779528,  47.62992126,\n",
       "         48.62204724,  49.61417323,  50.60629921,  51.5984252 ,\n",
       "         52.59055118,  53.58267717,  54.57480315,  55.56692913,\n",
       "         56.55905512,  57.5511811 ,  58.54330709,  59.53543307,\n",
       "         60.52755906,  61.51968504,  62.51181102,  63.50393701,\n",
       "         64.49606299,  65.48818898,  66.48031496,  67.47244094,\n",
       "         68.46456693,  69.45669291,  70.4488189 ,  71.44094488,\n",
       "         72.43307087,  73.42519685,  74.41732283,  75.40944882,\n",
       "         76.4015748 ,  77.39370079,  78.38582677,  79.37795276,\n",
       "         80.37007874,  81.36220472,  82.35433071,  83.34645669,\n",
       "         84.33858268,  85.33070866,  86.32283465,  87.31496063,\n",
       "         88.30708661,  89.2992126 ,  90.29133858,  91.28346457,\n",
       "         92.27559055,  93.26771654,  94.25984252,  95.2519685 ,\n",
       "         96.24409449,  97.23622047,  98.22834646,  99.22047244,\n",
       "        100.21259843, 101.20472441, 102.19685039, 103.18897638,\n",
       "        104.18110236, 105.17322835, 106.16535433, 107.15748031,\n",
       "        108.1496063 , 109.14173228, 110.13385827, 111.12598425,\n",
       "        112.11811024, 113.11023622, 114.1023622 , 115.09448819,\n",
       "        116.08661417, 117.07874016, 118.07086614, 119.06299213,\n",
       "        120.05511811, 121.04724409, 122.03937008, 123.03149606,\n",
       "        124.02362205, 125.01574803, 126.00787402, 127.        ]),\n",
       " <BarContainer object of 127 artists>)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(singletons, bins=127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singletons.count(127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition, target = sample_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 27, 42, 58, 74, 122, 125]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = np.zeros(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding[condition] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding[target] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 1, 128, 128])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing batch manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = th.zeros(3,128,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 122, 58, 42, 27, 125, 74]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7, 128, 128])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch[:, condition].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 116]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 128, 128])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch[:, target].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
