{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from utils import sample_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_mask(indices, size=128):\n",
    "    mask = torch.zeros(size, dtype=torch.bool)\n",
    "    mask[indices] = True\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.rand(batch_size, 128, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 128, 128])\n",
      "tensor(True)\n",
      "torch.Size([128, 128, 128])\n",
      "tensor(True)\n",
      "torch.Size([128, 128, 128])\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(batch):\n",
    "    print(item.shape)\n",
    "    print(torch.all(item == batch[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition, target, encoding = sample_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[80, 71, 61, 17, 74, 78, 83, 103, 52]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_mask = indices_to_mask(condition)\n",
    "target_mask = indices_to_mask(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_mask = condition_mask | target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([118, 128, 128])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0, ~combined_mask].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLD DESIGN - TOO MANY INPUT/OUTPUT CHANNELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.zeros_like(batch)\n",
    "timesteps_tensor = torch.zeros(batch_size)\n",
    "encoding_tensor = torch.zeros(batch_size, 128)\n",
    "\n",
    "for i, image in enumerate(batch):\n",
    "    condition, target, encoding = sample_indices()\n",
    "    \n",
    "    condition_mask = indices_to_mask(condition)\n",
    "    target_mask = indices_to_mask(target)\n",
    "    combined_mask = condition_mask | target_mask\n",
    "\n",
    "    image[target_mask] = noise_scheduler.add_noise(image[target_mask], noise, timesteps)\n",
    "    image[~combined_mask] = 0\n",
    "\n",
    "    input_tensor[i] = image\n",
    "    encoding_tensor[i] = encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(110)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0, 128, ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEW DESIGN\n",
    "\n",
    "May need to change encoding to be a 20 length vector of indices\n",
    "\n",
    "Or should also encode whether they are condition or target - so concatenate both to make 40 length vector of indices? Seems wrong but we should just try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([0, 128, 128]) torch.Size([1, 128, 128]) 1\n",
      "torch.Size([1, 128, 128])\n",
      "torch.Size([8, 128, 128]) torch.Size([3, 128, 128]) 11\n",
      "torch.Size([11, 128, 128])\n",
      "torch.Size([4, 128, 128]) torch.Size([2, 128, 128]) 6\n",
      "torch.Size([6, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "for i, image in enumerate(batch):\n",
    "    condition, target = sample_indices()\n",
    "\n",
    "    num_slices = len(condition) + len(target)\n",
    "\n",
    "    condition_mask = indices_to_mask(condition)\n",
    "    target_mask = indices_to_mask(target)\n",
    "\n",
    "    print(image[condition_mask].shape, image[target_mask].shape, num_slices)\n",
    "\n",
    "    target_slices = image[target_mask]\n",
    "    condition_slices = image[condition_mask]\n",
    "\n",
    "    print(torch.cat((target_slices, condition_slices)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(condition + [0] * (20 - len(condition)) + target + [0] * (20 - len(target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEWER IDEA\n",
    "\n",
    "Input size is 16\n",
    "\n",
    "You always have 8 target slices\n",
    "Sometimes you have no condition slices, otherwise you also have 8\n",
    "\n",
    "For the encoding, you have a two-hot encoding\n",
    "\n",
    "Keep target and condition slices ordered... or maybe more robust if you don't do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2184232158997489"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import sample_16_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([54, 78, 29, 80, 30, 44, 90, 31],\n",
       " [],\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_16_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 39,  66, 125])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0, 128, (3,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
